{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask App to run sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1 gives us the sentiment score for each sentence in the text/post/comment etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 1: DO NOT RUN \n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentiments(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    \n",
    "    return sentiments\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    sentiments = get_sentiments(body)\n",
    "    return flask.json.dumps(sentiments)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! flask --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code for get sentiments [approach 1] without the flask setup\n",
    "\n",
    "#analyzer = vader.SentimentIntensityAnalyzer()\n",
    "#english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "#def get_sentiments(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    #return sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to get the overall sentiment by taking the avg of sentiments of each sentence in the text/comment/post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_sentimentscore(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    #sentimentscore = 0\n",
    "    #for i in range(len(sentiments)):\n",
    "        #sentimentscore+=sentiments[i]['compound']\n",
    "        #overallsentiment=sentimentscore/len(sentiments)\n",
    "    #return overallsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sentimentscore('i love your content. i also like the product in general but i hate the service')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated approach [overall sentiment instead of individual sentiment scores for each sentence]\n",
    "\n",
    "#### This approach focuses on POST request where you will recieve overall sentiment of the text which you give the API using body of REST api in json form as shown in output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 2a : Get the overall sentiment score for all the texts involved in a document for a post request \n",
    "#### [mention the document with the text involved as json object]\n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using restapi client like postman, typing the following in body tab \n",
    "\n",
    "document = [\n",
    "    {\n",
    "        'text': 'product is amazing!!!'\n",
    "    },\n",
    "    {\n",
    "        'text': 'product is good'\n",
    "    },\n",
    "    {\n",
    "        'text': 'poorly designed'\n",
    "    },\n",
    "    {\n",
    "        'text': 'BAD, BAD , BAD'\n",
    "    }\n",
    "]\n",
    "\n",
    "##### will give an overall sentiment score of 0.025012500000000007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slight modification from approach 2a here that we can get the dictionaries of texts in a document along with the overall sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 2b \n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return [text,overallsentiment]\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### output for the same body content as stated in approach 2a will give us \n",
    "\n",
    "[\"document = [\\n {\\n 'text': 'product is amazing!!!'\\n },\\n {\\n 'text': 'product is good'\\n },\\n {\\n 'text': 'poorly\n",
    "designed'\\n },\\n {\\n 'text': 'BAD, BAD , BAD'\\n }\\n]\", 0.025012500000000007]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GET method to recieve sentiment score for a sentence mentioned within the python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we mention the sentence for which sentiment has to be evaluated.\n",
    "\n",
    "#### note: here the sentence is a string and not a list of strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 3 [Using GET method to recieve sentiment score for a sentence mentioned within the python environment]\n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "sentence = 'The product is in a bad shape!'\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "\n",
    "@app.route(\"/\") ##decorator \n",
    "@app.route(\"/sentence\")\n",
    "def index():\n",
    "    overallsentiment = get_sentimentscore(sentence)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "    return jsonify(sentence)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the output above can be returned using http://127.0.0.1:5000/sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for getting the overall sentiment score for a list of strings/texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentdr = ['the product is bad!', 'the product is really bad']\n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "get_sentimentscore(documentdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the above function for a dataframe pandas column containing the posts made by Fitbit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('fitbitdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatext = pd.DataFrame(data, columns = ['text']) \n",
    "json = datatext.to_json() \n",
    "print(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textjson=data['text'][0:999]\n",
    "jsont = textjson.to_json() \n",
    "print(jsont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# parse x:\n",
    "datatextjson = json.loads(jsont)\n",
    "\n",
    "datatextjson.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "#document = data['text']\n",
    "\n",
    "document = data['text'] \n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "get_sentimentscore(document) #where document is the list of strings/text for which overall sentiment score has to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "document = data['text']\n",
    "\n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "get_sentimentscore(document) \n",
    "\n",
    "\n",
    "@app.route(\"/\") ##decorator \n",
    "@app.route(\"/document\")\n",
    "def index():\n",
    "    overallsentiment = get_sentimentscore(document)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "    return jsonify(document)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the above will give us the desired overall sentiment score but will take a few seconds due to the 3000+ texts/posts involved in the fitbit data csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a post method endpoint named text where you can specify the text you want to analyze with sentimentscore. This gives us two endpoints here, first is the get method to retrieve the overall sentiment score for the document [fitbit posts here] and we have option to get sentiments of a random text using post method with /text endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "from flask import Flask, jsonify, request\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "document = data['text']\n",
    "\n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "get_sentimentscore(document) \n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "\n",
    "@app.route(\"/\") ##decorator \n",
    "@app.route(\"/document\")\n",
    "def index():\n",
    "    overallsentiment = get_sentimentscore(document)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "    return jsonify(document)\n",
    "@app.route('/text', methods=['POST'] )\n",
    "def add_text():\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentiment(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 2a : Get the overall sentiment score for all the texts involved in a document for a post request \n",
    "#### [mention the document with the text involved as json object]\n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "def summarysentiment(text):\n",
    "    \n",
    "\n",
    "\n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route('/summary', methods=['POST'] )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import flask\n",
    "#import spacy\n",
    "#import vaderSentiment.vaderSentiment as vader\n",
    "#from flask import Flask, jsonify\n",
    "\n",
    "#app = flask.Flask(__name__)\n",
    "#analyzer = vader.SentimentIntensityAnalyzer()\n",
    "#english = spacy.load(\"en\")\n",
    "\n",
    "#document = data['text']\n",
    "\n",
    "#document = data['text'] \n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "get_sentimentscore(document) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 2a : Get the overall sentiment score for all the texts involved in a document for a post request \n",
    "#### [mention the document with the text involved as json object]\n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Approach 2a : Get the overall sentiment score for all the texts involved in a document for a post request \n",
    "#### [mention the document with the text involved as json object]\n",
    "\n",
    "\n",
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "def get_summary(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    summaryscore=[maxscore,minscore]\n",
    "    return summaryscore\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "\n",
    "\n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #return sentiments [if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentimentscore(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentimentscore(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [[analyzer.polarity_scores(str(s)),str(s)] for s in result]\n",
    "    #return sentiments\n",
    "    \n",
    "    compoundlist=[]\n",
    "    for i in range(len(sentiments)):\n",
    "        compoundlist.append([sentiments[i][0]['compound'], sentiments[i][1]])\n",
    "    #return compoundlist\n",
    "    #print ('The max sentiment score is {}'.format(max(compoundlist)))\n",
    "    #print ('The min sentiment score is {}'.format(min(compoundlist)))\n",
    "    summary=[max(compoundlist), min(compoundlist)]\n",
    "    return summary\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #return sentiments #[if run sentiments, it gives all the sentiment scores for each sentence in the data]\n",
    "    #sentimentscore = 0\n",
    "    #for i in range(len(sentiments)):\n",
    "        #sentimentscore+=sentiments[i]['compound']\n",
    "        #overallsentiment=sentimentscore/len(sentiments)\n",
    "    #return overallsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "#app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "#get_sentimentscore(data['text'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    summaryscore=[maxscore,minscore]\n",
    "    return summaryscore\n",
    "    #return sentiments\n",
    "    #seq = [x['compound'] for x in sentiments]\n",
    "    #return [max(seq),min(seq)]\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(data['text'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summaryd(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    return sentiments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summaryd(data['text'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The one that works well for overall sentiments and summary in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "def get_summary(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    summaryscore=[maxscore,minscore]\n",
    "    return summaryscore\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "\n",
    "\n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# parse x:\n",
    "datatextjson = json.loads(jsont)\n",
    "\n",
    "datatextjson.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(textlist):\n",
    "    result=[]\n",
    "    for i in range(len(textlist)):\n",
    "        result.append(english(textlist[i]))\n",
    " \n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in result]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    return [mostnegativesentiment,mostpositivesentiment]\n",
    "\n",
    "    #maxscore = [max(sentiments[i][1] for i in range(len(sentiments)))]\n",
    "    #return maxscore\n",
    "                \n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(data['text'][0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The one that works with overallscore and summary with added posts along with pos and neg score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "#def get_summary(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore\n",
    "\n",
    "def get_summary(text):\n",
    "    result = english(text)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in sentences]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    #summaryscore=[mostnegativesentiment,mostpositivesentiment]\n",
    "    summaryscore= ('The most negative comment and score is {}'.format(mostnegativesentiment)), 'The most positive statement is {}'.format(mostpositivesentiment)\n",
    "    return summaryscore\n",
    "\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "\n",
    "\n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean   \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "#def get_summary(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore\n",
    "\n",
    "def get_summary(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean  \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in sentences]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    #summaryscore=[mostnegativesentiment,mostpositivesentiment]\n",
    "    summaryscore= ('The most negative comment and score is {}'.format(mostnegativesentiment)), 'The most positive statement is {}'.format(mostpositivesentiment)\n",
    "    return summaryscore\n",
    "\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "\n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "def index():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #text = (text.lower() for text in text) \n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(data['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Authorization with username and password specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from flask import request, jsonify, make_response\n",
    "from functools import wraps\n",
    "#from flask_restful import Resource, Api\n",
    "from flask_httpauth import HTTPTokenAuth\n",
    "#from flask import request\n",
    "app = flask.Flask(__name__)\n",
    "#auth = HTTPTokenAuth(scheme='Bearer')\n",
    "\n",
    "#tokens = {\n",
    "    #\"secret-token-1\": \"john\",\n",
    "    #\"secret-token-2\": \"susan\"\n",
    "#}\n",
    "\n",
    "#@auth.verify_token\n",
    "#def verify_token(token):\n",
    "    #if token in tokens:\n",
    "        #return tokens[token]\n",
    "\n",
    "#api = Api(app, prefix=\"/api/v1\")\n",
    "#auth = HTTPBasicAuth()\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "def auth_required(f):\n",
    "    @wraps(f)\n",
    "    def decorated(*args, **kwargs):\n",
    "        auth=request.authorization\n",
    "        if auth and auth.username == 'sparrowmktg' and auth.password == 'sentimentanalyzer':\n",
    "            return f(*args, **kwargs)\n",
    "        return make_response ('Could not verify your login!', 401, {'WWW-authenticate': 'Basic Realm=\"Login Required\"'})\n",
    "    return decorated\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean   \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "#def get_summary(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore\n",
    "\n",
    "def get_summary(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean  \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in sentences]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    #summaryscore=[mostnegativesentiment,mostpositivesentiment]\n",
    "    summaryscore= ('The most negative comment and score is {}'.format(mostnegativesentiment)), 'The most positive statement is {}'.format(mostpositivesentiment)\n",
    "    return summaryscore\n",
    "\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "@app.route('/')\n",
    "def index():\n",
    "    if request.authorization and request.authorization.username == 'sparrowmktg' and request.authorization.password == 'sentimentanalyzer':\n",
    "        return 'You are logged in'\n",
    "    return make_response('Could not verify!', 401, {'WWW-authenticate': 'Basic Realm=\"Login Required\"'})\n",
    "    \n",
    "    \n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "@auth_required\n",
    "def overallsentiment():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "@auth_required\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "import re\n",
    "import nltk\n",
    "import jwt\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from flask import request, jsonify, make_response\n",
    "from functools import wraps\n",
    "#from flask_restful import Resource, Api\n",
    "from flask_httpauth import HTTPTokenAuth\n",
    "#from flask import request\n",
    "app = flask.Flask(__name__)\n",
    "app.config['SECRET-KEY'] = 'sentiment2020'\n",
    "#auth = HTTPTokenAuth(scheme='Bearer')\n",
    "\n",
    "#tokens = {\n",
    "    #\"secret-token-1\": \"john\",\n",
    "    #\"secret-token-2\": \"susan\"\n",
    "#}\n",
    "\n",
    "#@auth.verify_token\n",
    "#def verify_token(token):\n",
    "    #if token in tokens:\n",
    "        #return tokens[token]\n",
    "\n",
    "#api = Api(app, prefix=\"/api/v1\")\n",
    "#auth = HTTPBasicAuth()\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "def token_required(f):\n",
    "    @wraps(f)\n",
    "    def decorated(*args, **kwargs):\n",
    "        token=request.args.get('token')\n",
    "        \n",
    "        if not token:\n",
    "            return jsonify({'message':'token is missing!'}), 403\n",
    "        \n",
    "        try:\n",
    "            data = jwt.decode(token, app.config['SECRET-KEY'])\n",
    "        except:\n",
    "            return jsonify({'message':'token is invalid!'}), 403\n",
    "        \n",
    "        return f(*args, **kwargs)\n",
    "    return decorated\n",
    "        \n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean   \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "#def get_summary(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore\n",
    "\n",
    "def get_summary(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean  \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in sentences]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    #summaryscore=[mostnegativesentiment,mostpositivesentiment]\n",
    "    summaryscore= ('The most negative comment and score is {}'.format(mostnegativesentiment)), 'The most positive statement is {}'.format(mostpositivesentiment)\n",
    "    return summaryscore\n",
    "\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "@app.route('/')\n",
    "def index():\n",
    "    auth=request.authorization\n",
    "    if auth and auth.username ==\"sparrowmk\" and auth.password == 'sentimentanalyzer':\n",
    "        token=jwt.encode({'user':auth.username,'exp':datetime.datetime.utcnow()+datetime.timedelta(minutes=15)}, app.config['SECRET-KEY'])\n",
    "        return jsonify({'token': token.decode('utf-8')})\n",
    "    return make_response('Could not verify!', 401, {'WWW-authenticate': 'Basic Realm=\"Login Required\"'})\n",
    "    \n",
    "    \n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "@token_required\n",
    "def overallsentiment():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "@token_required\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyjwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import spacy\n",
    "import vaderSentiment.vaderSentiment as vader\n",
    "import re\n",
    "import nltk\n",
    "import jwt\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from flask import request, jsonify, make_response\n",
    "from functools import wraps\n",
    "#from flask_restful import Resource, Api\n",
    "from flask_httpauth import HTTPTokenAuth\n",
    "#from flask import request\n",
    "app = flask.Flask(__name__)\n",
    "app.config['SECRET-KEY'] = 'sentiment2020'\n",
    "#auth = HTTPTokenAuth(scheme='Bearer')\n",
    "\n",
    "#tokens = {\n",
    "    #\"secret-token-1\": \"john\",\n",
    "    #\"secret-token-2\": \"susan\"\n",
    "#}\n",
    "\n",
    "#@auth.verify_token\n",
    "#def verify_token(token):\n",
    "    #if token in tokens:\n",
    "        #return tokens[token]\n",
    "\n",
    "#api = Api(app, prefix=\"/api/v1\")\n",
    "#auth = HTTPBasicAuth()\n",
    "analyzer = vader.SentimentIntensityAnalyzer()\n",
    "english = spacy.load(\"en\")\n",
    "\n",
    "def token_required(f):\n",
    "    @wraps(f)\n",
    "    def decorated(*args, **kwargs):\n",
    "        token=None\n",
    "        #print(request.headers)\n",
    "        if 'authorization' in request.headers:\n",
    "            token=request.headers['authorization'].replace('Bearer ','')\n",
    "        \n",
    "        \n",
    "        if not token:\n",
    "            return jsonify({'message':'token is missing!'}), 403\n",
    "        \n",
    "        #try:\n",
    "            #data = jwt.decode(token, app.config['SECRET-KEY'])\n",
    "        #except:\n",
    "            #return jsonify({'message':'token is invalid!'}), 403\n",
    "        if token != app.config['SECRET-KEY']:\n",
    "            return jsonify({'message':'token is invalid!'}), 403\n",
    "        return f(*args, **kwargs)\n",
    "    return decorated\n",
    "        \n",
    "\n",
    "\n",
    "def get_sentimentscore(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean   \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [analyzer.polarity_scores(str(s)) for s in sentences]\n",
    "    sentimentscore = 0\n",
    "    for i in range(len(sentiments)):\n",
    "        sentimentscore+=sentiments[i]['compound']\n",
    "        overallsentiment=sentimentscore/len(sentiments)\n",
    "    return overallsentiment\n",
    "\n",
    "#def get_summary(text):\n",
    "    #result = english(text)\n",
    "    #sentences = [str(sent) for sent in result.sents]\n",
    "    #sentiments = [analyzer.polarity_scores(str(s)) for s in result]\n",
    "    #maxscore = max(sentiments, key=lambda x:x['compound'])\n",
    "    #minscore = min(sentiments, key=lambda x:x['compound'])\n",
    "    #summaryscore=[maxscore,minscore]\n",
    "    #return summaryscore\n",
    "\n",
    "def get_summary(text):\n",
    "    #def clean_text(text):\n",
    "    text_clean = \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_clean = ' '.join(word for word in text_clean.split() if word not in stop_words)\n",
    "    text_clean = ' '.join(word.lower() for word in text_clean.split())\n",
    "    #from nltk.corpus import stopwords\n",
    "    #text = [text for text if word not in stopwords.words('english')]\n",
    "    #return text_clean  \n",
    "    result = english(text_clean)\n",
    "    sentences = [str(sent) for sent in result.sents]\n",
    "    sentiments = [[s,analyzer.polarity_scores(str(s))['compound']] for s in sentences]\n",
    "    #return sentiments\n",
    "    mostnegativesentiment=(sorted(sentiments, key = lambda x: x[1])[0])  \n",
    "    mostpositivesentiment=(sorted(sentiments, key = lambda x: x[1],reverse =True)[0])\n",
    "    #summaryscore=[mostnegativesentiment,mostpositivesentiment]\n",
    "    summaryscore= ('The most negative comment and score is {}'.format(mostnegativesentiment)), 'The most positive statement is {}'.format(mostpositivesentiment)\n",
    "    return summaryscore\n",
    "\n",
    "\n",
    "    \n",
    "    #compoundlist=[]\n",
    "    #for i in range(len(sentiments)):\n",
    "        #compoundlist.append(sentiments[i]['compound'])\n",
    "    #return [max(compoundlist),min(compoundlist)]\n",
    "#@app.route('/')\n",
    "#def index():\n",
    "    #auth=request.authorization\n",
    "    #if auth and auth.username ==\"sparrowmk\" and auth.password == 'sentimentanalyzer':\n",
    "        #token=jwt.encode({'user':auth.username,'exp':datetime.datetime.utcnow()+datetime.timedelta(minutes=15)}, app.config['SECRET-KEY'])\n",
    "        #return jsonify({'token': token.decode('utf-8')})\n",
    "    #return make_response('Could not verify!', 401, {'WWW-authenticate': 'Basic Realm=\"Login Required\"'})\n",
    "    \n",
    "    \n",
    "@app.route(\"/overallsentiment\", methods=[\"POST\", \"GET\"])\n",
    "@token_required\n",
    "def overallsentiment():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    overallsentiment = get_sentimentscore(body)\n",
    "    return flask.json.dumps(overallsentiment)\n",
    "@app.route(\"/summary\", methods=[\"POST\", \"GET\"])\n",
    "@token_required\n",
    "def summaryscore():\n",
    "    if flask.request.method == \"GET\":\n",
    "        return \"To access this service send a POST request to this URL with\" \\\n",
    "               \" the text you want analyzed in the body.\"\n",
    "    body = flask.request.data.decode(\"utf-8\")\n",
    "    summaryscore=get_summary(body)\n",
    "    return flask.json.dumps(summaryscore)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
